---
output:
  word_document: default
  html_document: default
---

Load the files: the new employees data and the hays data

```{r}
data <- read.csv(file = "employees2.csv", fileEncoding="UTF-8-BOM")
income_data <- read.csv(file = "hays_salary_survey.csv")[-c(2,3,4)] #use post tax figures

```
map the industry income ranges to our data

```{r}
lower <- income_data[match(data$JobRole,income_data$JobRole),][2]
upper <- income_data[match(data$JobRole,income_data$JobRole),][3]

#classify the monthly income
data$IndustryRange <- ifelse(
data$MonthlyIncome < lower,
"Below Range",
ifelse(
data$MonthlyIncome >= lower & data$MonthlyIncome< upper,
"Within Range",
"Above Range")
)
```
Enrich the data

```{r}
data$IsAttrition <- ifelse(data$Attrition == "Yes",1,0) 

data$IsManagement <- ifelse(
  data$JobRole == c("Manager", "Manufacturing Director", 
                    "Research Director", "Sales Executive"),
  "Yes",
  "No"
)
```

Linear Model lmIncome

```{r}
numRows <- nrow(data)
set.seed(57) #changed from 57
train <- sample(numRows, 0.8*numRows)
dataTrain <- data[train, ]
dataTest <- data[-train,]

```

Linear modelling Linear.Model.01

```{r}
Linear.Model.01 <- lm(
formula = YearsAtCompany ~ .,
data = dataTrain
)
summary(Linear.Model.01)

```
Use leaps package to work out which combinations best explain target

```{r}
library(leaps)
bestSubset <- regsubsets(
YearsAtCompany ~ .,
data = dataTrain,
nvmax = 24 #number of dependant variables
)
summary(bestSubset)
```

```{r}
coef(bestSubset, 1:24)
```

```{r}
summary(bestSubset)$bic # Get all of the adjusted R^2 values
```
Judging which model is best there are different metrics

```{r}
which.max(summary(bestSubset)$adjr2)
which.min(summary(bestSubset)$rss)
which.min(summary(bestSubset)$cp)
which.min(summary(bestSubset)$bic)
```
Plotting the best(bic, for example) measure

```{r}
plot(
summary(bestSubset)$bic,
type = "l",
main = "Figure 1: Number variables by BIC",
xlab = "Number of Variables",
ylab = "BIC",
)

bestBIC = which.min(summary(bestSubset)$bic)
points(    #showing the point with lowest bic for example
x = bestBIC,
y = summary(bestSubset)$bic[bestBIC],
col = "red",
pch = "x"
)
```

```{r}
coef(bestSubset, 5)
coef(bestSubset, 17)
coef(bestSubset, 22)
```
```{r}
#linear models deemed by by regsubsets, bic and c scores
#best 5
Linear.Model.02 <- lm(
            formula = YearsAtCompany ~ NumCompaniesWorked + TotalWorkingYears + YearsInCurrentRole +     YearsSinceLastPromotion + YearsWithCurrManager ,
            data = dataTrain,
            
)

#best 17
Linear.Model.03 <- lm(
            formula = YearsAtCompany ~ Department+DistanceFromHome+EnvironmentSatisfaction+Gender+
                JobInvolvement+JobRole+NumCompaniesWorked+RelationshipSatisfaction+TotalWorkingYears+
                YearsInCurrentRole+YearsSinceLastPromotion +YearsWithCurrManager+IndustryRange+IsManagement,
            data = dataTrain,
            
)

#Best 22

Linear.Model.04 <- lm(
            formula = YearsAtCompany ~ Age+Department+DistanceFromHome+EnvironmentSatisfaction+
                Gender+JobInvolvement+JobRole+NumCompaniesWorked+
                PerformanceRating+RelationshipSatisfaction+StockOptionLevel+
                TotalWorkingYears+TrainingTimesLastYear+WorkLifeBalance+
                YearsInCurrentRole+YearsSinceLastPromotion+YearsWithCurrManager+
                IndustryRange+IsManagement,
            data = dataTrain,
            
)



```
```{r}
#final test on linear models deemed by by regsubsets, bic and c scores
dataTest$PredictionYears.lm02 <- predict(
                                  Linear.Model.02,
                                  newdata = dataTest,
                                  type = "response"
)
dataTest$PredictionYears.lm03 <- predict(
                                  Linear.Model.03,
                                  newdata = dataTest,
                                  type = "response"
)

dataTest$PredictionYears.lm02 <- predict(
                                  Linear.Model.02,
                                  newdata = dataTest,
                                  type = "response"
)
dataTest$PredictionYears.lm04 <- predict(
                                  Linear.Model.04,
                                  newdata = dataTest,
                                  type = "response"
)

mean((dataTest$YearsAtCompany - dataTest$PredictionYears.lm02)^2) #least so it is best
mean((dataTest$YearsAtCompany - dataTest$PredictionYears.lm03)^2)
mean((dataTest$YearsAtCompany - dataTest$PredictionYears.lm04)^2)

#what about on train data

dataTrain$PredictionYears.lm02 <- predict(
                                  Linear.Model.02,
                                  newdata = dataTrain,
                                  type = "response"
)
dataTrain$PredictionYears.lm03 <- predict(
                                  Linear.Model.03,
                                  newdata = dataTrain,
                                  type = "response"
)
summary(Linear.Model.02)
mean((dataTrain$YearsAtCompany - dataTrain$PredictionYears.lm02)^2) #least so it is best
mean((dataTrain$YearsAtCompany - dataTrain$PredictionYears.lm03)^2)

```
Making Linear.Model.02 a classifier

```{r}
#Classification Rule

dataTest$PredictionAttrition02 <- ifelse(
  (dataTest$YearsAtCompany+0.5) > dataTest$PredictionYears.lm02 ,
  "Yes", 
  "No"
  )

  

#Confusion matrix 

conf_matrix02 <- table(dataTest$PredictionAttrition02, dataTest$IsAttrition)
accuracy.gLinear.Model.02.test <- sum(diag(conf_matrix02))/sum(conf_matrix02)
accuracy.gLinear.Model.02.test

```


```{r}
#checking assumptions of linearility
par(mfrow = c(1,3))
plot(Linear.Model.02$residuals, col = "blue", ylab = "Residuals")
hist(Linear.Model.02$residuals, xlab = "Residulas", main = "Residual plots")
boxplot(Linear.Model.02$residuals)
```


Logistic modelling


```{r}
#gml model with all variables 
gLinear.Model.05 <- glm(
          IsAttrition ~  Age +BusinessTravel +Department + 
                         DistanceFromHome +Education + EnvironmentSatisfaction + 
                         Gender + JobInvolvement + JobRole + 
                         MaritalStatus + MonthlyIncome + NumCompaniesWorked + 
                         OverTime + PerformanceRating +StockOptionLevel +
                         TotalWorkingYears +TrainingTimesLastYear +WorkLifeBalance +
                         YearsAtCompany  +YearsInCurrentRole + YearsSinceLastPromotion  +
                         YearsWithCurrManager +IndustryRange ,
    data = dataTrain,
    family = binomial,
    control = list(maxit = 27)
)

summary(gLinear.Model.05)

gLinear.Model.06 <- glm(
          IsAttrition ~ Age +DistanceFromHome + EnvironmentSatisfaction + 
                        JobInvolvement + JobRole + MaritalStatus  + 
                        NumCompaniesWorked + OverTime   +YearsInCurrentRole + 
                        YearsSinceLastPromotion  +YearsWithCurrManager +RelationshipSatisfaction,
    data = dataTrain,
    family = binomial,
    control = list(maxit = 27)
)
summary(gLinear.Model.06)

```


gLm preditions

```{r}
dataTest$ProbabilityAttrition05 <- predict(
        gLinear.Model.05,
        newdata = dataTest,
        type = "response"
)

dataTest$ProbabilityAttrition06 <- predict(
        gLinear.Model.06,
        newdata = dataTest,
        type = "response"
)

dataTest$PredictionAttrition05 <- ifelse(dataTest$ProbabilityAttrition05 > 0.5, 1, 0)
dataTest$PredictionAttrition06 <- ifelse(dataTest$ProbabilityAttrition06 > 0.5, 1, 0)

boxplot(
  dataTest$ProbabilityAttrition06 ~ dataTest$Attrition
  
)

boxplot(
  dataTest$ProbabilityAttrition05 ~ dataTest$Attrition
  
)
#Confusion matrix 

conf_matrixAll <- table(dataTest$PredictionAttrition05, dataTest$IsAttrition)
accuracy.gLinear.Model.05.test <- sum(diag(conf_matrixAll))/sum(conf_matrixAll)
accuracy.gLinear.Model.05.test

conf_matrixSig <- table(dataTest$PredictionAttrition06, dataTest$IsAttrition)
accuracy.gLinear.Model.06.test <- sum(diag(conf_matrixSig))/sum(conf_matrixSig)
accuracy.gLinear.Model.06.test
```

Accuracy on Train data

```{r}
dataTrain$ProbabilityAttrition05 <- predict(
        gLinear.Model.05,
        newdata = dataTrain,
        type = "response"
)

dataTrain$ProbabilityAttrition06 <- predict(
        gLinear.Model.06,
        newdata = dataTrain,
        type = "response"
)

dataTrain$PredictionAttrition05 <- ifelse(dataTrain$ProbabilityAttrition05 > 0.5, 1, 0)
dataTrain$PredictionAttrition06 <- ifelse(dataTrain$ProbabilityAttrition06 > 0.5, 1, 0)

#Confusion matrix 

(conf_matrixAll.train <- table(dataTrain$PredictionAttrition05, dataTrain$IsAttrition))
accuracy.gLinear.Model.05.train <- sum(diag(conf_matrixAll.train))/sum(conf_matrixAll.train)
accuracy.gLinear.Model.05.train

conf_matrixSig.train <- table(dataTrain$PredictionAttrition06, dataTrain$IsAttrition)
accuracy.gLinear.Model.06.train <- sum(diag(conf_matrixSig.train))/sum(conf_matrixSig.train)
accuracy.gLinear.Model.06.train



```

```{r}
#Variable importance Linear.Model.02 and gLinear.Model.06

library(caret)

old_par <- par(no.readonly=TRUE)
par(
    mar = c(4, 12, 1, 1),
    cex = 0.7
)
barplot(
  t(varImp(gLinear.Model.06, scale = FALSE)),
  main = "gLinear.Model.06 Variable Importance",
  las = 2,
  horiz = TRUE
  )

par(
    mar = c(4, 8, 1, 1),
    cex = 0.7
) 


barplot(
  t(varImp(Linear.Model.02, scale = FALSE)),
  main = "Linear.Model.02 Variable Importance",
  col = "blue",
  las = 2,
 
)
par(old_par)
```


Modelling with a Decision Tree

```{r}

library(rpart)
library(rpart.plot)

tree <- rpart(
            Attrition ~ Age +BusinessTravel +Department + 
              DistanceFromHome + Education + EnvironmentSatisfaction + 
              Gender + JobInvolvement + JobRole + MaritalStatus + 
              MonthlyIncome + NumCompaniesWorked + OverTime + 
              PerformanceRating +StockOptionLevel +TotalWorkingYears +
              TrainingTimesLastYear +WorkLifeBalance +YearsAtCompany  +
              YearsInCurrentRole + YearsSinceLastPromotion  +YearsWithCurrManager +
              IndustryRange + RelationshipSatisfaction + IsManagement,
        data = dataTrain,
        method = "class",
        minsplit=20, #smallest number of observations in the parent node that could be split further.default is 20.
        minbucket = 1 #smallest number of observations that are allowed in a terminal node
)

prp(tree,cex = 0.6,box.palette = "auto") 

tree

```
```{r}
dataTest$PredictionTree <-predict(
  tree,
  newdata = dataTest,
  type = "class"
)
Probability.Tree <-predict(
  tree,
  newdata = dataTest
  
)

conf_matrixTree <- table(dataTest$PredictionTree, dataTest$Attrition)
accuracy.Tree.test <- sum(diag(conf_matrixTree))/sum(conf_matrixTree)
accuracy.Tree.test

dataTrain$PredictionTree <-predict(
  tree,
  newdata = dataTrain,
  type = "class"
)

conf_matrixTree.train <- table(dataTrain$PredictionTree, dataTrain$Attrition)
accuracy.Tree.train <- sum(diag(conf_matrixTree.train))/sum(conf_matrixTree.train)
accuracy.Tree.train

```
Random forest

```{r}

library(randomForest)
require(caTools)
random.forest <- randomForest(
  IsAttrition ~ Age +BusinessTravel +Department + DistanceFromHome +
                Education + EnvironmentSatisfaction + Gender + 
                JobInvolvement + JobRole + MaritalStatus + 
                MonthlyIncome + NumCompaniesWorked + OverTime + 
                PerformanceRating +StockOptionLevel +TotalWorkingYears +
                TrainingTimesLastYear +WorkLifeBalance +YearsAtCompany  +
                YearsInCurrentRole + YearsSinceLastPromotion  +YearsWithCurrManager +
                IndustryRange + IsManagement,
  data = dataTrain,
  parms=list(split="information")
)

dataTest$PredRF.probability <-predict(
                random.forest,
                newdata = dataTest
                
)
dataTest$PredRF <- ifelse(dataTest$PredRF.probability > 0.5, 1, 0)

conf_matrixRF.test <- table(dataTest$PredRF, dataTest$IsAttrition)
accuracy.RF.test <- sum(diag(conf_matrixRF.test))/sum(conf_matrixRF.test)
accuracy.RF.test

boxplot(
  dataTest$PredRF.probability ~ dataTest$Attrition
  
)

#Variable importance plots for tree and RF
old_par <- par(no.readonly=TRUE)
par(
    mar = c(3, 11, 1, 1),
    cex = 0.7
    
)
barplot(
  t(tree$variable.importance),
  las = 2,
  col = "blue",
  horiz = TRUE,
  main = "Decision Tree"
  )

barplot(
  t(random.forest$importance),
  las = 2,
  col = 'lightgrey',
  horiz = TRUE,
  main = "Random Forest"
  )
par(old_par)

summary(random.forest)

```
What about on training set

```{r}
dataTrain$PredRF.probability <-predict(
                random.forest,
                newdata = dataTrain,
                
)
dataTrain$PredRF <- ifelse(dataTrain$PredRF.probability > 0.5, 1, 0)

conf_matrixRF.Train <- table(dataTrain$PredRF, dataTrain$IsAttrition)
accuracy.RF.Train <- sum(diag(conf_matrixRF.Train))/sum(conf_matrixRF.Train)
accuracy.RF.Train
```
```{r}
#plot of the models perfomance
par(mfcol = c(2,2))
library(vcd)
mosaic(
  structable(conf_matrix02),
  labeling = labeling_values, 
  pop = FALSE, 
  main = "Linear.Model.02")
mosaic(
  structable(conf_matrixAll),
  labeling = labeling_values, 
  pop = FALSE, 
  main = "gLinear.Model.05")

mosaic(
  structable(conf_matrixSig),
  labeling = labeling_values, 
  pop = FALSE, 
  main = "gLinear.Model.06")

mosaic(
  structable(conf_matrixTree),
  labeling = labeling_values, 
  pop = FALSE, 
  main = "Decision Tree")

mosaic(
  structable(conf_matrixRF.test),
  labeling = labeling_values, 
  pop = FALSE, 
  main = "Random Forest")

library(cutpointr)
tpr <- tpr(c(11,9,4,5), c(9,11,16,15))
fpr <- fpr(c(102,12,9,5), c(78,168,171,175))
tnr <-tnr(c(102,12,9,5), c(78,168,171,175))
fnr <- fnr(c(11,9,4,5), c(9,11,16,15))
models.summary <- data.frame(Model = c("Linear.Model.02(classifier)","gLinear.Model.06","Decision Tree","Random Forest"), TPR = tpr,FPR = fpr,TNR = tnr,FNR = fnr)
models.summary

```
Comparing LMs and GLMs
```{r}
library("rcompanion")
compareLM(Linear.Model.01,Linear.Model.02,Linear.Model.03)
compareGLM(gLinear.Model.05,gLinear.Model.06)
```

```{r}
#residuals plot
par(mfrow = c(1,3))
plot(gLinear.Model.06$residuals ~ dataTrain$ProbabilityAttrition06, col = "blue", ylab = "Residuals", xlab = "Predicted Probability")
boxplot(gLinear.Model.06$residuals)
hist(gLinear.Model.06$residuals, xlab = "Residulas", main ="")

```


Performance

```{r}
library(ROCR)

pred6 <- prediction(
  dataTest$ProbabilityAttrition06, dataTest$Attrition
  )
pred7 <- prediction(
  data.frame(Probability.Tree)$Yes, dataTest$Attrition
  )
pred8 <- prediction(
  dataTest$PredRF.probability, dataTest$Attrition
  )


#ROC curves

roc6 <- performance(pred6,"tpr","fpr")
roc7 <- performance(pred7,"tpr","fpr")
roc8 <- performance(pred8,"tpr","fpr")
plot(roc6, col = "blue", lwd = 2,main="Receiver Operating Characteristic Comparison")
plot(roc7, col = "magenta", lwd = 2, add = TRUE)
plot(roc8, col="orange", lwd = 2, add = TRUE)
abline(a = 0, b = 1)


#Lift
lift6 <- performance(pred6,"lift","rpp")
lift7 <- performance(pred7,"lift","rpp")
lift8 <- performance(pred8,"lift","rpp")
plot(lift6, col = "blue", lwd = 2, main = "Lift curve")
plot(lift7, col = "magenta", lwd = 2, add = TRUE)
plot(lift8, col="orange", lwd = 2, add = TRUE)

#Sensitivity - specificity

sens6 <- performance(pred6,"sens","spec")
sens7 <- performance(pred7,"sens","spec")
sens8 <- performance(pred8,"sens","spec")
plot(sens6, col = "blue", lwd = 2,main ="Sensitivity - Specificity")
plot(sens7, col = "magenta", lwd = 2, add = TRUE)
plot(sens8, col="orange", lwd = 2, add = TRUE)

```










